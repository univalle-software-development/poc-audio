# ConfiguraciÃ³n de Google Cloud Speech-to-Text

Este documento explica paso a paso cÃ³mo se implementÃ³ la funcionalidad de Speech-to-Text usando Google Cloud en nuestro POC de chat con IA.

## ğŸ“‹ Tabla de Contenidos

1. [Requisitos Previos](#requisitos-previos)
2. [ConfiguraciÃ³n en Google Cloud Platform](#configuraciÃ³n-en-google-cloud-platform)
3. [ImplementaciÃ³n en el Proyecto](#implementaciÃ³n-en-el-proyecto)
4. [Arquitectura y Flujo de Datos](#arquitectura-y-flujo-de-datos)
5. [Archivos Creados y Modificados](#archivos-creados-y-modificados)
6. [Seguridad y Mejores PrÃ¡cticas](#seguridad-y-mejores-prÃ¡cticas)
7. [Pruebas y VerificaciÃ³n](#pruebas-y-verificaciÃ³n)

---

## ğŸ¯ Requisitos Previos

Antes de comenzar, necesitas:

- âœ… Una cuenta de Google Cloud Platform (GCP)
- âœ… Un proyecto creado en GCP
- âœ… Tarjeta de crÃ©dito vinculada (Google ofrece $300 USD de crÃ©ditos gratuitos)
- âœ… Node.js y pnpm instalados
- âœ… Proyecto Next.js funcionando

---

## â˜ï¸ ConfiguraciÃ³n en Google Cloud Platform

### Paso 1: Crear/Seleccionar un Proyecto

1. Ve a [Google Cloud Console](https://console.cloud.google.com/)
2. En la barra superior, haz clic en el selector de proyectos
3. Crea un nuevo proyecto o selecciona uno existente
4. Dale un nombre descriptivo (ej: `poc-audio-speech-to-text`)

**Â¿Por quÃ©?** Cada proyecto en GCP es un espacio aislado con sus propias APIs, credenciales y facturaciÃ³n.

### Paso 2: Habilitar la API de Speech-to-Text

1. En el menÃº lateral, ve a **APIs & Services** â†’ **Library**
2. Busca "Cloud Speech-to-Text API"
3. Haz clic en la API y selecciona **Enable**
4. Espera unos segundos mientras se habilita

**Â¿Por quÃ©?** Por defecto, las APIs de Google Cloud estÃ¡n deshabilitadas. Habilitarla permite que tu proyecto pueda usarla.

### Paso 3: Crear Credenciales (API Key)

1. Ve a **APIs & Services** â†’ **Credentials**
2. Haz clic en **Create Credentials** â†’ **API Key**
3. Se generarÃ¡ una API key automÃ¡ticamente
4. **IMPORTANTE**: Copia la API key inmediatamente

**Â¿Por quÃ©?** La API key es como una contraseÃ±a que permite que tu aplicaciÃ³n se comunique con Google Cloud.

### Paso 4: Restringir la API Key (Seguridad)

1. Haz clic en la API key reciÃ©n creada (Ã­cono de lÃ¡piz/editar)
2. En **API restrictions**:
   - Selecciona "Restrict key"
   - Marca solo **"Cloud Speech-to-Text API"**
3. Guarda los cambios

**Â¿Por quÃ©?** Si alguien obtiene tu API key, solo podrÃ¡ usarla para Speech-to-Text, no para otros servicios de Google Cloud que podrÃ­an ser mÃ¡s costosos.

### Paso 5: Configurar la API Key en Variables de Entorno

Crea un archivo `.env.local` en la raÃ­z del proyecto:

```bash
GOOGLE_CLOUD_API_KEY=tu-api-key-aqui
```

**Â¿Por quÃ© `.env.local`?**
- âœ… EstÃ¡ en `.gitignore` por defecto (no se sube a GitHub)
- âœ… Next.js lo carga automÃ¡ticamente
- âœ… Las variables sin `NEXT_PUBLIC_` solo estÃ¡n disponibles en el servidor (mÃ¡s seguro)

---

## ğŸ’» ImplementaciÃ³n en el Proyecto

### Paso 1: InstalaciÃ³n de Dependencias

```bash
pnpm add @google-cloud/speech
```

**Â¿Por quÃ©?** Aunque usamos la REST API directamente, el paquete oficial de Google Cloud nos da tipos TypeScript y utilidades Ãºtiles.

### Paso 2: Crear el Endpoint de API

**Archivo**: `app/api/speech-to-text/route.ts`

```typescript
import { NextRequest, NextResponse } from "next/server";

export async function POST(request: NextRequest) {
  // 1. Recibir el archivo de audio del cliente
  const formData = await request.formData();
  const audioFile = formData.get("audio") as Blob;

  // 2. Convertir el audio a base64 (formato que acepta Google Cloud)
  const arrayBuffer = await audioFile.arrayBuffer();
  const base64Audio = Buffer.from(arrayBuffer).toString("base64");

  // 3. Obtener la API key de las variables de entorno
  const apiKey = process.env.GOOGLE_CLOUD_API_KEY;

  // 4. Llamar a la API de Google Cloud Speech-to-Text
  const response = await fetch(
    `https://speech.googleapis.com/v1/speech:recognize?key=${apiKey}`,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        config: {
          encoding: "WEBM_OPUS",        // Formato del audio del navegador
          sampleRateHertz: 48000,        // Calidad de audio
          languageCode: "es-ES",         // EspaÃ±ol como idioma principal
          alternativeLanguageCodes: ["en-US"], // InglÃ©s como fallback
        },
        audio: { content: base64Audio }
      }),
    }
  );

  // 5. Extraer y devolver la transcripciÃ³n
  const data = await response.json();
  const transcription = data.results
    ?.map((result: any) => result.alternatives[0]?.transcript)
    .join(" ") || "";

  return NextResponse.json({ transcription });
}
```

**Â¿Por quÃ© un endpoint de API?**
- âœ… La API key debe estar en el servidor, nunca en el frontend
- âœ… Next.js API Routes son serverless y escalables
- âœ… Podemos manejar errores y validaciones centralizadamente

**Â¿Por quÃ© estos parÃ¡metros?**
- **WEBM_OPUS**: Formato estÃ¡ndar que usan los navegadores modernos para grabaciÃ³n
- **48000 Hz**: Tasa de muestreo estÃ¡ndar para audio de alta calidad
- **es-ES**: Configurado para espaÃ±ol de EspaÃ±a (puedes cambiarlo)
- **alternativeLanguageCodes**: Si no detecta espaÃ±ol, intenta con inglÃ©s

### Paso 3: Crear el Hook de GrabaciÃ³n de Audio

**Archivo**: `hooks/use-speech-to-text.ts`

```typescript
export function useSpeechToText() {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState("");
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const startRecording = async () => {
    // 1. Pedir permiso para acceder al micrÃ³fono
    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: { channelCount: 1, sampleRate: 48000 } 
    });

    // 2. Crear el grabador de audio
    const mediaRecorder = new MediaRecorder(stream, {
      mimeType: "audio/webm;codecs=opus",
    });

    // 3. Guardar los chunks de audio mientras graba
    mediaRecorder.ondataavailable = (event) => {
      audioChunksRef.current.push(event.data);
    };

    // 4. Cuando se detiene, enviar a transcribir
    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(audioChunksRef.current, {
        type: "audio/webm;codecs=opus",
      });
      await transcribeAudio(audioBlob);
      stream.getTracks().forEach((track) => track.stop());
    };

    mediaRecorder.start();
    setIsRecording(true);
  };

  const transcribeAudio = async (audioBlob: Blob) => {
    const formData = new FormData();
    formData.append("audio", audioBlob);

    const response = await fetch("/api/speech-to-text", {
      method: "POST",
      body: formData,
    });

    const data = await response.json();
    setTranscript(data.transcription);
  };

  return { isRecording, transcript, startRecording, stopRecording };
}
```

**Â¿Por quÃ© un hook personalizado?**
- âœ… Reutilizable en cualquier componente
- âœ… Encapsula toda la lÃ³gica de grabaciÃ³n
- âœ… Maneja estados (grabando, transcripciÃ³n, errores)
- âœ… Sigue las mejores prÃ¡cticas de React

**Â¿QuÃ© hace MediaRecorder?**
- Es una API nativa del navegador
- Captura audio del micrÃ³fono
- Lo guarda en chunks (fragmentos) mientras graba
- Al detener, crea un Blob (archivo binario) con todo el audio

### Paso 4: Integrar en el Componente Chat

**Archivo**: `components/chat.tsx`

```typescript
import { useSpeechToText } from "@/hooks/use-speech-to-text";

function ChatInner() {
  const {
    isRecording,
    transcript,
    startRecording,
    stopRecording,
  } = useSpeechToText();

  // Cuando hay transcripciÃ³n, actualizar el input
  useEffect(() => {
    if (transcript) {
      handleInputChange({ target: { value: transcript } } as any);
    }
  }, [transcript]);

  const handleRecordingToggle = async () => {
    if (isRecording) {
      await stopRecording();
    } else {
      await startRecording();
    }
  };

  return (
    <button onClick={handleRecordingToggle}>
      {isRecording ? <StopIcon /> : <MicrophoneIcon />}
    </button>
  );
}
```

**Â¿Por quÃ© este flujo?**
- âœ… El hook maneja toda la complejidad
- âœ… El componente solo se preocupa de la UI
- âœ… Cuando hay transcripciÃ³n, se actualiza el input automÃ¡ticamente
- âœ… El usuario puede editar el texto antes de enviar

---

## ğŸ”„ Arquitectura y Flujo de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Usuario    â”‚
â”‚  (Habla)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. Click en micrÃ³fono
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Navegador                  â”‚
â”‚  - MediaRecorder API        â”‚
â”‚  - Graba audio en WebM Opus â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 2. Audio Blob
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hook: useSpeechToText      â”‚
â”‚  - Convierte a FormData     â”‚
â”‚  - EnvÃ­a a /api/speech-to-text â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 3. POST request
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js API Route          â”‚
â”‚  - Recibe audio             â”‚
â”‚  - Convierte a base64       â”‚
â”‚  - AÃ±ade API key            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 4. HTTPS request
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Google Cloud               â”‚
â”‚  Speech-to-Text API         â”‚
â”‚  - Procesa el audio         â”‚
â”‚  - Detecta idioma           â”‚
â”‚  - Transcribe               â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 5. JSON response
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js API Route          â”‚
â”‚  - Extrae transcripciÃ³n     â”‚
â”‚  - Formatea respuesta       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 6. TranscripciÃ³n
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hook: useSpeechToText      â”‚
â”‚  - Actualiza estado         â”‚
â”‚  - Trigger useEffect        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 7. Actualiza input
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chat Component             â”‚
â”‚  - Muestra transcripciÃ³n    â”‚
â”‚  - Usuario puede editar     â”‚
â”‚  - Enviar al chat           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Archivos Creados y Modificados

### Archivos Nuevos

1. **`app/api/speech-to-text/route.ts`**
   - Endpoint serverless de Next.js
   - Maneja la comunicaciÃ³n con Google Cloud
   - Protege la API key

2. **`hooks/use-speech-to-text.ts`**
   - Hook React personalizado
   - Maneja grabaciÃ³n de audio
   - Estados y lifecycle de la transcripciÃ³n

3. **`.env.local`** (no commitear)
   - Variables de entorno locales
   - API key de Google Cloud

### Archivos Modificados

1. **`components/chat.tsx`**
   - Import del hook `useSpeechToText`
   - IntegraciÃ³n del botÃ³n de micrÃ³fono
   - useEffect para actualizar input con transcripciÃ³n

2. **`.env`** (template)
   - Agregada variable `GOOGLE_CLOUD_API_KEY`
   - Sirve como referencia para otros desarrolladores

3. **`package.json`**
   - Agregada dependencia `@google-cloud/speech`

---

## ğŸ”’ Seguridad y Mejores PrÃ¡cticas

### âœ… Lo que hicimos bien

1. **API Key en el servidor**
   - âœ… La key nunca llega al navegador
   - âœ… Usamos Next.js API Routes (serverless)
   - âœ… Variable de entorno sin `NEXT_PUBLIC_`

2. **RestricciÃ³n de la API Key**
   - âœ… Solo puede usarse para Speech-to-Text
   - âœ… Limita el daÃ±o si se filtra

3. **`.env.local` en `.gitignore`**
   - âœ… Las credenciales no se suben a GitHub
   - âœ… Cada desarrollador usa sus propias keys

4. **Validaciones en el endpoint**
   - âœ… Verificamos que exista el archivo de audio
   - âœ… Verificamos que exista la API key
   - âœ… Manejamos errores de Google Cloud

### âš ï¸ Consideraciones de Seguridad

1. **Rate Limiting**: Considera agregar lÃ­mites de requests
2. **AutenticaciÃ³n**: En producciÃ³n, valida que el usuario estÃ© autenticado
3. **TamaÃ±o del archivo**: Limita el tamaÃ±o mÃ¡ximo del audio
4. **CORS**: Configura CORS si el frontend estÃ¡ en otro dominio

---

## ğŸ§ª Pruebas y VerificaciÃ³n

### Verificar que funciona

1. **Iniciar el servidor**:
   ```bash
   pnpm dev
   ```

2. **Abrir el navegador**: `http://localhost:3000`

3. **Hacer clic en el botÃ³n del micrÃ³fono**
   - Debe pedir permiso para usar el micrÃ³fono
   - El botÃ³n debe cambiar a rojo (grabando)

4. **Hablar claramente**

5. **Hacer clic de nuevo para detener**
   - El audio se envÃ­a a Google Cloud
   - La transcripciÃ³n aparece en el input
   - Puedes editar antes de enviar

### Debugging

Si algo falla, revisa:

1. **Console del navegador** (F12)
   - Errores de permisos del micrÃ³fono
   - Errores de fetch al endpoint

2. **Terminal del servidor** (donde corre `pnpm dev`)
   - Logs del endpoint `/api/speech-to-text`
   - Errores de Google Cloud API

3. **Verificar variables de entorno**
   ```typescript
   console.log("API Key set:", !!process.env.GOOGLE_CLOUD_API_KEY);
   ```

### Errores Comunes

| Error | SoluciÃ³n |
|-------|----------|
| "API Key not set" | Verifica que `.env.local` existe y tiene la key |
| "Permission denied" | Permite el acceso al micrÃ³fono en el navegador |
| "Invalid encoding" | El navegador puede no soportar WebM Opus |
| "Quota exceeded" | Llegaste al lÃ­mite gratuito de Google Cloud |

---

## ğŸ“Š Costos y LÃ­mites

### Capa Gratuita de Google Cloud

- **60 minutos gratis** por mes
- DespuÃ©s: **$0.006 USD** por 15 segundos de audio
- Para un POC, la capa gratuita es mÃ¡s que suficiente

### Optimizaciones

1. **Usar modelo `gpt-5-nano`** para el chat (mÃ¡s econÃ³mico)
2. **Limitar duraciÃ³n de grabaciÃ³n** (ej: mÃ¡ximo 30 segundos)
3. **Cachear respuestas comunes** si es aplicable

---

## ğŸš€ PrÃ³ximos Pasos

1. **Mejorar UX**: Agregar visualizaciÃ³n de onda de audio mientras graba
2. **Soporte multi-idioma**: Detectar idioma automÃ¡ticamente
3. **EdiciÃ³n de transcripciÃ³n**: Permitir corregir antes de enviar
4. **Historial**: Guardar transcripciones anteriores
5. **Analytics**: Trackear precisiÃ³n de las transcripciones

---

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n oficial de Google Cloud Speech-to-Text](https://cloud.google.com/speech-to-text/docs)
- [Next.js API Routes](https://nextjs.org/docs/app/building-your-application/routing/route-handlers)
- [MediaRecorder API](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)
- [React Custom Hooks](https://react.dev/learn/reusing-logic-with-custom-hooks)

---

## âœï¸ Notas Finales

Este documento fue creado para el proyecto **POC Audio - Cloud Speech-to-Text** de la Universidad del Valle, Proyecto Integrador II-01.

**Fecha**: Octubre 7, 2025  
**Autor**: GitHub Copilot  
**Repositorio**: `univalle-software-development/poc-audio`
